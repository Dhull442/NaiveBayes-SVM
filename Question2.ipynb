{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxopt as cv\n",
    "import math\n",
    "from sklearn import svm,multiclass\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "TRAIN_FILE = 'fashion_mnist/train.csv'\n",
    "TEST_FILE = 'fashion_mnist/test.csv'\n",
    "VAL_FILE = 'fashion_mnist/val.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from files\n",
    "data = np.genfromtxt(TRAIN_FILE,delimiter=',')\n",
    "tdata = np.genfromtxt(TEST_FILE,delimiter=',')\n",
    "vdata = np.genfromtxt(VAL_FILE,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1.0\n",
    "y = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classes to classify\n",
    "d = 0\n",
    "classes = [d, (d+1)%10] # Binary classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and modifying traindata\n",
    "# change values to [0,1] from [0,255]\n",
    "indices = np.where(data[:,-1] < 2)\n",
    "X = data[indices,0:784][0] / 255.0\n",
    "# change classes to {-1,1}\n",
    "Y = 2* data[indices,-1] -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading test data\n",
    "indices = np.where(tdata[:,-1] < 2)\n",
    "tY = 2 * (tdata[indices,-1])[0] -1\n",
    "tX = (tdata[indices,0:784]/255.0)[0]\n",
    "\n",
    "# Loading validation data\n",
    "indices = np.where(vdata[:,-1] < 2)\n",
    "vY = 2 * (vdata[indices,-1])[0] - 1\n",
    "vX = (vdata[indices,0:784]/255.0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns alphas as np array, train for both linear and gaussian\n",
    "def train(islinear,X,Y):\n",
    "    M = len(X)\n",
    "    P = np.eye(M).astype(float)\n",
    "    if(islinear):\n",
    "        print(\"Using Linear Kernel\")\n",
    "        # linear kernel\n",
    "        Z = Y.T * X\n",
    "        ## M x M array Linear kernel\n",
    "        P = np.matmul(Z, Z.T)\n",
    "    else:\n",
    "        print(\"Using Gaussian Kernel\")\n",
    "        for i in range(0,M):\n",
    "            t = X - X[i]\n",
    "            P[i] = np.sum(t**2,axis=1)\n",
    "        P = np.matmul(Y.T,Y) * GAUS(y,P)\n",
    "    P = cv.matrix(P)\n",
    "    # column vector with all -1\n",
    "    Q = cv.matrix(-1 * np.ones((M,1)).astype(float))\n",
    "    G = cv.matrix(np.vstack((-1 * np.eye(M).astype(float),np.eye(M).astype(float))))\n",
    "    h = cv.matrix(np.vstack((np.zeros((M,1)).astype(float),C * np.ones((M,1)).astype(float))))\n",
    "    A = cv.matrix(Y)\n",
    "    b = cv.matrix([[0]],tc='d')\n",
    "    print(\"Finding the optimal solution:\")\n",
    "    solution = cv.solvers.qp(P,Q,G,h,A,b)\n",
    "    return np.array(solution['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Kernel\n",
    "def gaussian(y,v):\n",
    "    return math.exp(-y * v)\n",
    "GAUS = np.vectorize(gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traingaus(GP,Y,M):\n",
    "#     M = len(Y)\n",
    "    print(\"Training on gaussian kernel\")\n",
    "    P = cv.matrix(np.matmul(Y.T,Y) * GP)\n",
    "    # column vector with all -1\n",
    "    Q = cv.matrix(-1 * np.ones((M,1)).astype(float))\n",
    "    G = cv.matrix(np.vstack((-1 * np.eye(M).astype(float),np.eye(M).astype(float))))\n",
    "    h = cv.matrix(np.vstack((np.zeros((M,1)).astype(float),C * np.ones((M,1)).astype(float))))\n",
    "    A = cv.matrix(Y)\n",
    "    b = cv.matrix([[0]],tc='d')\n",
    "    print(\"Finding the optimal solution:\")\n",
    "    solution = cv.solvers.qp(P,Q,G,h,A,b)\n",
    "    return np.array(solution['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getB(ALPHA,GP):\n",
    "    R = np.sum(ALPHA * GP, axis=0)\n",
    "    M = len(R)\n",
    "    ## assuming arangement is such that top layers is Y = -1 and bottom is Y = 1\n",
    "    maxv = np.max(R[0:M/2])\n",
    "    minv = np.min(R[M/2:])\n",
    "    b = -(maxv + minv)/2.0\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLinearParams(alph,X,Y):\n",
    "    fw = alph * Y.T\n",
    "    w = np.matmul(fw.T,X)\n",
    "    R = np.matmul(w,X.T)[0]\n",
    "    Y = Y[0]\n",
    "    y1indices = np.where(Y==1)\n",
    "    y0indices = np.where(Y==-1)\n",
    "    maxv = np.max(R[y0indices])\n",
    "    minv = np.min(R[y1indices])\n",
    "    b = -(maxv+minv)/2.0\n",
    "    nsv = len(np.where(alph > 1e-05)[0])\n",
    "    return (w,b,nsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Linear Kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.2916e+02 -9.3878e+03  5e+04  3e+00  3e-12\n",
      " 1: -2.0018e+02 -5.2391e+03  1e+04  4e-01  2e-12\n",
      " 2: -9.3627e+01 -1.6503e+03  3e+03  8e-02  1e-12\n",
      " 3: -5.1870e+01 -7.1316e+02  1e+03  3e-02  8e-13\n",
      " 4: -2.9393e+01 -4.7263e+02  7e+02  2e-02  5e-13\n",
      " 5: -1.8616e+01 -2.5482e+02  4e+02  7e-03  4e-13\n",
      " 6: -1.5942e+01 -8.1551e+01  9e+01  2e-03  4e-13\n",
      " 7: -1.7889e+01 -4.1759e+01  3e+01  4e-04  4e-13\n",
      " 8: -1.9475e+01 -3.1857e+01  1e+01  8e-05  4e-13\n",
      " 9: -1.9419e+01 -2.8941e+01  1e+01  3e-16  4e-13\n",
      "10: -2.1921e+01 -2.4878e+01  3e+00  9e-16  4e-13\n",
      "11: -2.2590e+01 -2.3752e+01  1e+00  2e-16  4e-13\n",
      "12: -2.3023e+01 -2.3203e+01  2e-01  4e-15  4e-13\n",
      "13: -2.3099e+01 -2.3108e+01  1e-02  2e-15  4e-13\n",
      "14: -2.3103e+01 -2.3103e+01  2e-04  5e-15  4e-13\n",
      "15: -2.3103e+01 -2.3103e+01  2e-06  9e-16  4e-13\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "linearalpha = train(True,X,Y)\n",
    "(W,b,nsv) = getLinearParams(linearalpha,X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Support Vectors: 198\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Support Vectors: \"+str(nsv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: -1.6282084222780322\n"
     ]
    }
   ],
   "source": [
    "print(\"b: \"+str(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.982\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "testValues = (np.matmul(W,tX.T) + b)[0]\n",
    "testPrediction = [1 if val>=0 else -1 for val in testValues]\n",
    "testCorrect = len(np.where(testPrediction == tY)[0])\n",
    "testAccuracy = float(testCorrect)/float(len(tY))\n",
    "print(\"Test Accuracy: \" + str(testAccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.974\n"
     ]
    }
   ],
   "source": [
    "# validation data\n",
    "validationValues = (np.matmul(W,vX.T) + b)[0]\n",
    "validationPrediction = [1 if val >=0 else -1 for val in validationValues]\n",
    "validationCorrect = len(np.where(validationPrediction==vY)[0])\n",
    "validationAccuracy = float(validationCorrect)/float(len(vY))\n",
    "print(\"Validation Accuracy: \"+str(validationAccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Squared sum matrix\n",
    "M = len(X)\n",
    "SSM = np.eye(M).astype(float)\n",
    "for i in range(0,M):\n",
    "    SSM[i] = np.sum((X-X[i])**2,axis=1)\n",
    "# Gaussian of SSM\n",
    "GM = GAUS(y,SSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.6492e+02 -6.6070e+03  3e+04  2e+00  1e-15\n",
      " 1: -1.1407e+02 -3.0686e+03  5e+03  2e-01  2e-15\n",
      " 2: -1.0459e+02 -7.6952e+02  9e+02  3e-02  2e-15\n",
      " 3: -1.2684e+02 -3.0203e+02  2e+02  6e-03  2e-15\n",
      " 4: -1.4133e+02 -2.0101e+02  6e+01  1e-03  1e-15\n",
      " 5: -1.4945e+02 -1.6809e+02  2e+01  2e-04  1e-15\n",
      " 6: -1.5144e+02 -1.6280e+02  1e+01  3e-05  1e-15\n",
      " 7: -1.5364e+02 -1.5728e+02  4e+00  7e-06  1e-15\n",
      " 8: -1.5443e+02 -1.5550e+02  1e+00  9e-16  1e-15\n",
      " 9: -1.5478e+02 -1.5492e+02  1e-01  7e-15  1e-15\n",
      "10: -1.5483e+02 -1.5484e+02  4e-03  1e-14  1e-15\n",
      "11: -1.5483e+02 -1.5483e+02  6e-05  1e-14  1e-15\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "gaussianalpha = traingaus(GM,Y,M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "fW = gaussianalpha * Y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Support Vectors: 834\n"
     ]
    }
   ],
   "source": [
    "nsv = len(np.where(gaussianalpha>1e-05)[0])\n",
    "print(\"Number of Support Vectors: \"+str(nsv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: -0.0009552690776055139\n"
     ]
    }
   ],
   "source": [
    "# Get B\n",
    "tmp = np.sum(fW * GM, axis=0)\n",
    "y1indices = np.where(Y[0]==1)\n",
    "yn1indices = np.where(Y[0]==-1)\n",
    "maxv = np.max(tmp[yn1indices])\n",
    "minv = np.min(tmp[y1indices])\n",
    "b = -(maxv + minv)/2.0\n",
    "print(\"b: \"+str(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.993\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "tSSM = np.ones((len(X),len(tX))).astype(float)\n",
    "for i in range(0,len(X)):\n",
    "    tSSM[i] = np.sum((tX - X[i])**2,axis = 1)\n",
    "tGM = GAUS(y,tSSM)\n",
    "testValues = np.sum(fW* tGM, axis=0) + b\n",
    "testPrediction = [1 if val>=0 else -1 for val in testValues]\n",
    "testCorrect = len(np.where(testPrediction == tY)[0])\n",
    "testAccuracy = float(testCorrect)/float(len(tY))\n",
    "print(\"Test Accuracy: \" + str(testAccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.978\n"
     ]
    }
   ],
   "source": [
    "# Validation data\n",
    "vSSM = np.ones((len(X),len(vX))).astype(float)\n",
    "for i in range(0,len(X)):\n",
    "    vSSM[i] = np.sum((vX - X[i])**2,axis = 1)\n",
    "vGM = GAUS(y,vSSM)\n",
    "validationValues = np.sum(fW* vGM, axis=0) + b\n",
    "validationPrediction = [1 if val>=0 else -1 for val in validationValues]\n",
    "validationCorrect = len(np.where(validationPrediction == vY)[0])\n",
    "validationAccuracy = float(validationCorrect)/float(len(vY))\n",
    "print(\"Validation Accuracy: \" + str(validationAccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "linearclf = svm.SVC(C=1.0,kernel='linear')\n",
    "linearclf.fit(X,Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Support Vectors = 198\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Support Vectors = \"+str(np.sum(linearclf.n_support_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "R = linearclf.predict(tX)\n",
    "Correct = len(np.where(R == tY)[0])\n",
    "print(\"Test Accuracy: \"+str(float(Correct)/float(len(R))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.978\n"
     ]
    }
   ],
   "source": [
    "# Validation data\n",
    "R = linearclf.predict(vX)\n",
    "Correct = len(np.where(R == vY)[0])\n",
    "print(\"Validation Accuracy: \"+str(float(Correct)/float(len(R))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.05, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "gaussianclf = svm.SVC(C=1.0,kernel='rbf',gamma=y)\n",
    "gaussianclf.fit(X,Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Support Vectors = 811\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Support Vectors = \"+str(np.sum(gaussianclf.n_support_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.989\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "R = gaussianclf.predict(tX)\n",
    "Correct = len(np.where(R == tY)[0])\n",
    "print(\"Test Accuracy: \"+str(float(Correct)/float(len(R))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.986\n"
     ]
    }
   ],
   "source": [
    "# Validation data\n",
    "R = gaussianclf.predict(vX)\n",
    "Correct = len(np.where(R == vY)[0])\n",
    "print(\"Validation Accuracy: \"+str(float(Correct)/float(len(R))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Class Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "allX = data[:,0:784] / 255.0\n",
    "Y = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict containing all rows for a class in class key\n",
    "X = {}\n",
    "for i in range(0,len(allX)):\n",
    "    if Y[i] not in X:\n",
    "        X[Y[i]] = [allX[i]]\n",
    "    else:\n",
    "        X[Y[i]].append(allX[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alphas and b for different classes\n",
    "ALPHAxY = np.zeros((10,10,4500,1)).astype(float)\n",
    "b = np.zeros((10,10)).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved Alphas and b\n",
    "ALPHAxY = np.load('alphxy.npy')\n",
    "b = np.load('b.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ip(G,X,i):\n",
    "    G[i] = np.sum((X-X[i])**2, axis=1)\n",
    "IP = np.vectorize(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for 0 1\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.6492e+02 -6.6070e+03  3e+04  2e+00  4e-15\n",
      " 1: -1.1407e+02 -3.0686e+03  5e+03  2e-01  4e-15\n",
      " 2: -1.0459e+02 -7.6952e+02  9e+02  3e-02  4e-15\n",
      " 3: -1.2684e+02 -3.0203e+02  2e+02  6e-03  4e-15\n",
      " 4: -1.4133e+02 -2.0101e+02  6e+01  1e-03  3e-15\n",
      " 5: -1.4945e+02 -1.6809e+02  2e+01  2e-04  3e-15\n",
      " 6: -1.5144e+02 -1.6280e+02  1e+01  3e-05  3e-15\n",
      " 7: -1.5364e+02 -1.5728e+02  4e+00  7e-06  3e-15\n",
      " 8: -1.5443e+02 -1.5550e+02  1e+00  7e-14  3e-15\n",
      " 9: -1.5478e+02 -1.5492e+02  1e-01  2e-13  3e-15\n",
      "10: -1.5483e+02 -1.5484e+02  4e-03  5e-14  4e-15\n",
      "11: -1.5483e+02 -1.5483e+02  6e-05  2e-14  4e-15\n",
      "Optimal solution found.\n",
      "131.822613955\n",
      "training for 0 2\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.7366e+02 -8.4330e+03  4e+04  2e+00  4e-15\n",
      " 1: -2.8341e+02 -4.5691e+03  7e+03  2e-01  5e-15\n",
      " 2: -2.6181e+02 -1.1549e+03  1e+03  3e-02  5e-15\n",
      " 3: -3.1375e+02 -5.8168e+02  3e+02  6e-03  5e-15\n",
      " 4: -3.4227e+02 -4.1865e+02  8e+01  1e-03  5e-15\n",
      " 5: -3.5409e+02 -3.7849e+02  2e+01  2e-04  5e-15\n",
      " 6: -3.5907e+02 -3.6537e+02  6e+00  2e-05  5e-15\n",
      " 7: -3.6070e+02 -3.6180e+02  1e+00  2e-06  5e-15\n",
      " 8: -3.6105e+02 -3.6113e+02  8e-02  1e-07  5e-15\n",
      " 9: -3.6108e+02 -3.6108e+02  2e-03  3e-09  5e-15\n",
      "10: -3.6108e+02 -3.6108e+02  4e-05  4e-11  5e-15\n",
      "Optimal solution found.\n",
      "260.521622896\n",
      "training for 0 3\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.0649e+02 -8.5038e+03  4e+04  2e+00  8e-15\n",
      " 1: -4.0102e+02 -4.7685e+03  7e+03  2e-01  1e-14\n",
      " 2: -3.8628e+02 -1.1830e+03  9e+02  2e-02  1e-14\n",
      " 3: -4.5117e+02 -7.2740e+02  3e+02  6e-03  9e-15\n",
      " 4: -4.8441e+02 -5.8062e+02  1e+02  1e-03  1e-14\n",
      " 5: -5.0013e+02 -5.2734e+02  3e+01  2e-05  1e-14\n",
      " 6: -5.0580e+02 -5.1293e+02  7e+00  1e-06  1e-14\n",
      " 7: -5.0772e+02 -5.0866e+02  9e-01  1e-12  1e-14\n",
      " 8: -5.0800e+02 -5.0814e+02  1e-01  8e-14  1e-14\n",
      " 9: -5.0805e+02 -5.0806e+02  6e-03  2e-13  1e-14\n",
      "10: -5.0805e+02 -5.0805e+02  2e-04  6e-14  1e-14\n",
      "Optimal solution found.\n",
      "376.047832966\n",
      "training for 0 4\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6859e+02 -7.0722e+03  3e+04  2e+00  4e-15\n",
      " 1: -1.9279e+02 -3.5589e+03  5e+03  2e-01  4e-15\n",
      " 2: -1.7237e+02 -8.6876e+02  9e+02  3e-02  4e-15\n",
      " 3: -2.1276e+02 -4.3671e+02  3e+02  7e-03  4e-15\n",
      " 4: -2.3708e+02 -3.0397e+02  7e+01  1e-03  3e-15\n",
      " 5: -2.4834e+02 -2.6677e+02  2e+01  3e-04  3e-15\n",
      " 6: -2.5227e+02 -2.5748e+02  5e+00  6e-05  3e-15\n",
      " 7: -2.5364e+02 -2.5461e+02  1e+00  4e-13  4e-15\n",
      " 8: -2.5398e+02 -2.5404e+02  5e-02  6e-13  4e-15\n",
      " 9: -2.5400e+02 -2.5401e+02  1e-03  3e-13  4e-15\n",
      "10: -2.5400e+02 -2.5400e+02  3e-05  1e-13  4e-15\n",
      "Optimal solution found.\n",
      "490.38398695\n",
      "training for 0 5\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.9696e+02 -7.3592e+03  3e+04  2e+00  3e-15\n",
      " 1: -1.3157e+02 -3.7922e+03  6e+03  2e-01  2e-15\n",
      " 2: -1.0046e+02 -9.5864e+02  1e+03  4e-02  5e-15\n",
      " 3: -1.3521e+02 -3.4380e+02  2e+02  7e-03  2e-15\n",
      " 4: -1.5380e+02 -2.1468e+02  6e+01  8e-04  2e-15\n",
      " 5: -1.6312e+02 -1.8376e+02  2e+01  2e-14  2e-15\n",
      " 6: -1.6683e+02 -1.7392e+02  7e+00  4e-13  2e-15\n",
      " 7: -1.6823e+02 -1.7056e+02  2e+00  2e-13  2e-15\n",
      " 8: -1.6889e+02 -1.6928e+02  4e-01  1e-13  2e-15\n",
      " 9: -1.6902e+02 -1.6904e+02  2e-02  4e-13  2e-15\n",
      "10: -1.6903e+02 -1.6903e+02  3e-04  5e-13  2e-15\n",
      "11: -1.6903e+02 -1.6903e+02  4e-06  2e-13  2e-15\n",
      "Optimal solution found.\n",
      "607.491107941\n",
      "training for 0 6\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0396e+03 -9.5846e+03  4e+04  2e+00  1e-14\n",
      " 1: -8.6974e+02 -5.8661e+03  7e+03  2e-01  2e-14\n",
      " 2: -8.9358e+02 -1.8092e+03  1e+03  2e-02  2e-14\n",
      " 3: -9.9727e+02 -1.2864e+03  3e+02  5e-03  2e-14\n",
      " 4: -1.0441e+03 -1.1319e+03  9e+01  8e-04  2e-14\n",
      " 5: -1.0607e+03 -1.0851e+03  2e+01  2e-04  2e-14\n",
      " 6: -1.0662e+03 -1.0717e+03  6e+00  3e-05  2e-14\n",
      " 7: -1.0675e+03 -1.0687e+03  1e+00  4e-06  2e-14\n",
      " 8: -1.0679e+03 -1.0679e+03  5e-02  3e-08  2e-14\n",
      " 9: -1.0679e+03 -1.0679e+03  1e-03  6e-10  2e-14\n",
      "Optimal solution found.\n",
      "715.435499907\n",
      "training for 0 7\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0789e+02 -7.4144e+03  4e+04  2e+00  3e-15\n",
      " 1: -5.8581e+01 -3.7245e+03  6e+03  3e-01  2e-15\n",
      " 2: -1.8417e+01 -8.7407e+02  1e+03  4e-02  4e-15\n",
      " 3: -3.8829e+01 -1.9635e+02  2e+02  5e-03  3e-15\n",
      " 4: -5.5771e+01 -1.0639e+02  5e+01  1e-03  2e-15\n",
      " 5: -6.3792e+01 -8.0947e+01  2e+01  1e-04  2e-15\n",
      " 6: -6.7399e+01 -7.2673e+01  5e+00  2e-05  1e-15\n",
      " 7: -6.8657e+01 -7.0232e+01  2e+00  1e-06  1e-15\n",
      " 8: -6.9169e+01 -6.9365e+01  2e-01  9e-09  1e-15\n",
      " 9: -6.9247e+01 -6.9257e+01  1e-02  4e-10  2e-15\n",
      "10: -6.9251e+01 -6.9251e+01  2e-04  6e-12  2e-15\n",
      "11: -6.9251e+01 -6.9251e+01  3e-06  2e-13  2e-15\n",
      "Optimal solution found.\n",
      "833.028904915\n",
      "training for 0 8\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.7984e+02 -7.6220e+03  3e+04  2e+00  3e-15\n",
      " 1: -2.0299e+02 -4.0371e+03  6e+03  2e-01  2e-15\n",
      " 2: -1.7493e+02 -1.2336e+03  1e+03  4e-02  3e-15\n",
      " 3: -2.1659e+02 -4.2387e+02  2e+02  6e-03  2e-15\n",
      " 4: -2.4162e+02 -2.9524e+02  6e+01  7e-04  2e-15\n",
      " 5: -2.5192e+02 -2.6612e+02  1e+01  1e-04  2e-15\n",
      " 6: -2.5529e+02 -2.5891e+02  4e+00  2e-05  2e-15\n",
      " 7: -2.5634e+02 -2.5681e+02  5e-01  8e-07  2e-15\n",
      " 8: -2.5650e+02 -2.5653e+02  3e-02  4e-08  2e-15\n",
      " 9: -2.5651e+02 -2.5651e+02  6e-04  7e-10  2e-15\n",
      "10: -2.5651e+02 -2.5651e+02  1e-05  1e-11  2e-15\n",
      "Optimal solution found.\n",
      "944.743855953\n",
      "training for 0 9\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.3464e+02 -6.8388e+03  3e+04  2e+00  2e-15\n",
      " 1: -7.6690e+01 -3.2910e+03  5e+03  2e-01  2e-15\n",
      " 2: -5.4390e+01 -6.8811e+02  8e+02  3e-02  3e-15\n",
      " 3: -8.6653e+01 -2.4599e+02  2e+02  5e-03  2e-15\n",
      " 4: -1.0255e+02 -1.5246e+02  5e+01  1e-03  1e-15\n",
      " 5: -1.0963e+02 -1.2739e+02  2e+01  3e-04  1e-15\n",
      " 6: -1.1318e+02 -1.1820e+02  5e+00  4e-05  1e-15\n",
      " 7: -1.1445e+02 -1.1556e+02  1e+00  4e-06  1e-15\n",
      " 8: -1.1479e+02 -1.1496e+02  2e-01  5e-07  1e-15\n",
      " 9: -1.1485e+02 -1.1486e+02  5e-03  9e-09  1e-15\n",
      "10: -1.1485e+02 -1.1485e+02  1e-04  2e-10  1e-15\n",
      "Optimal solution found.\n",
      "1057.51462388\n",
      "training for 1 2\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.3552e+02 -7.1330e+03  3e+04  2e+00  3e-15\n",
      " 1: -8.6508e+01 -3.3924e+03  5e+03  2e-01  2e-15\n",
      " 2: -7.2456e+01 -7.5584e+02  9e+02  3e-02  3e-15\n",
      " 3: -9.8211e+01 -2.9087e+02  2e+02  6e-03  2e-15\n",
      " 4: -1.1260e+02 -1.7965e+02  7e+01  2e-03  2e-15\n",
      " 5: -1.2011e+02 -1.4295e+02  2e+01  3e-04  2e-15\n",
      " 6: -1.2381e+02 -1.3099e+02  7e+00  1e-13  2e-15\n",
      " 7: -1.2520e+02 -1.2765e+02  2e+00  2e-13  2e-15\n",
      " 8: -1.2579e+02 -1.2645e+02  7e-01  1e-13  2e-15\n",
      " 9: -1.2601e+02 -1.2606e+02  5e-02  6e-14  2e-15\n",
      "10: -1.2603e+02 -1.2603e+02  1e-03  4e-14  2e-15\n",
      "11: -1.2603e+02 -1.2603e+02  1e-05  5e-14  2e-15\n",
      "Optimal solution found.\n",
      "1174.95784187\n",
      "training for 1 3\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.2920e+02 -7.6513e+03  4e+04  2e+00  5e-15\n",
      " 1: -1.5609e+02 -3.9103e+03  6e+03  2e-01  6e-15\n",
      " 2: -1.3600e+02 -9.2629e+02  1e+03  3e-02  6e-15\n",
      " 3: -1.7295e+02 -4.3323e+02  3e+02  7e-03  6e-15\n",
      " 4: -1.9647e+02 -2.7544e+02  8e+01  1e-03  6e-15\n",
      " 5: -2.0746e+02 -2.3515e+02  3e+01  1e-04  5e-15\n",
      " 6: -2.1226e+02 -2.2191e+02  1e+01  2e-05  5e-15\n",
      " 7: -2.1376e+02 -2.1815e+02  4e+00  4e-14  6e-15\n",
      " 8: -2.1495e+02 -2.1581e+02  9e-01  1e-14  6e-15\n",
      " 9: -2.1517e+02 -2.1539e+02  2e-01  7e-14  6e-15\n",
      "10: -2.1525e+02 -2.1526e+02  7e-03  3e-13  6e-15\n",
      "11: -2.1526e+02 -2.1526e+02  1e-04  3e-13  6e-15\n",
      "Optimal solution found.\n",
      "1292.72414494\n",
      "training for 1 4\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.2784e+02 -6.4239e+03  3e+04  2e+00  3e-15\n",
      " 1: -8.0058e+01 -2.9152e+03  4e+03  2e-01  2e-15\n",
      " 2: -6.9558e+01 -6.4681e+02  7e+02  3e-02  3e-15\n",
      " 3: -9.4376e+01 -2.5073e+02  2e+02  5e-03  2e-15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4: -1.0877e+02 -1.5571e+02  5e+01  7e-04  2e-15\n",
      " 5: -1.1554e+02 -1.3286e+02  2e+01  1e-04  2e-15\n",
      " 6: -1.1887e+02 -1.2384e+02  5e+00  2e-06  2e-15\n",
      " 7: -1.2010e+02 -1.2121e+02  1e+00  3e-14  2e-15\n",
      " 8: -1.2044e+02 -1.2063e+02  2e-01  1e-13  2e-15\n",
      " 9: -1.2051e+02 -1.2052e+02  1e-02  2e-15  2e-15\n",
      "10: -1.2052e+02 -1.2052e+02  2e-04  9e-14  2e-15\n",
      "11: -1.2052e+02 -1.2052e+02  9e-06  1e-13  2e-15\n",
      "Optimal solution found.\n",
      "1410.99896193\n",
      "training for 1 5\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.3956e+01 -6.5185e+03  3e+04  2e+00  2e-15\n",
      " 1: -5.0069e+01 -2.9491e+03  5e+03  2e-01  2e-15\n",
      " 2: -3.9046e+01 -6.7825e+02  8e+02  3e-02  2e-15\n",
      " 3: -6.0172e+01 -2.0557e+02  2e+02  5e-03  2e-15\n",
      " 4: -7.2614e+01 -1.1949e+02  5e+01  1e-03  2e-15\n",
      " 5: -7.7575e+01 -9.6388e+01  2e+01  1e-04  1e-15\n",
      " 6: -7.9825e+01 -8.8992e+01  9e+00  2e-13  1e-15\n",
      " 7: -8.1322e+01 -8.4537e+01  3e+00  2e-13  1e-15\n",
      " 8: -8.1909e+01 -8.3041e+01  1e+00  7e-14  1e-15\n",
      " 9: -8.2190e+01 -8.2488e+01  3e-01  3e-14  1e-15\n",
      "10: -8.2279e+01 -8.2332e+01  5e-02  5e-14  1e-15\n",
      "11: -8.2299e+01 -8.2300e+01  2e-03  6e-14  1e-15\n",
      "12: -8.2299e+01 -8.2299e+01  2e-05  5e-14  1e-15\n",
      "Optimal solution found.\n",
      "1532.27563286\n",
      "training for 1 6\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.6321e+02 -6.5609e+03  3e+04  2e+00  3e-15\n",
      " 1: -1.1075e+02 -3.0589e+03  5e+03  2e-01  3e-15\n",
      " 2: -1.0167e+02 -7.6887e+02  9e+02  3e-02  3e-15\n",
      " 3: -1.2535e+02 -3.1952e+02  2e+02  7e-03  3e-15\n",
      " 4: -1.4028e+02 -2.0638e+02  7e+01  2e-03  3e-15\n",
      " 5: -1.4794e+02 -1.7118e+02  2e+01  2e-04  2e-15\n",
      " 6: -1.5107e+02 -1.6136e+02  1e+01  1e-05  2e-15\n",
      " 7: -1.5295e+02 -1.5632e+02  3e+00  3e-06  2e-15\n",
      " 8: -1.5376e+02 -1.5442e+02  7e-01  2e-13  3e-15\n",
      " 9: -1.5397e+02 -1.5405e+02  8e-02  1e-15  2e-15\n",
      "10: -1.5400e+02 -1.5400e+02  2e-03  6e-14  3e-15\n",
      "11: -1.5400e+02 -1.5400e+02  6e-05  1e-13  2e-15\n",
      "Optimal solution found.\n",
      "1648.71522403\n",
      "training for 1 7\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.5955e+01 -6.5221e+03  3e+04  2e+00  2e-15\n",
      " 1: -3.1834e+01 -2.9574e+03  5e+03  2e-01  2e-15\n",
      " 2: -1.0088e+01 -5.1383e+02  7e+02  2e-02  3e-15\n",
      " 3: -2.7978e+01 -1.2024e+02  1e+02  3e-03  2e-15\n",
      " 4: -3.8190e+01 -7.0454e+01  3e+01  8e-04  2e-15\n",
      " 5: -4.2441e+01 -5.6406e+01  1e+01  3e-04  1e-15\n",
      " 6: -4.4726e+01 -5.0658e+01  6e+00  5e-05  1e-15\n",
      " 7: -4.5554e+01 -4.8795e+01  3e+00  2e-14  1e-15\n",
      " 8: -4.6276e+01 -4.7407e+01  1e+00  9e-14  1e-15\n",
      " 9: -4.6545e+01 -4.6900e+01  4e-01  2e-14  1e-15\n",
      "10: -4.6685e+01 -4.6706e+01  2e-02  3e-14  1e-15\n",
      "11: -4.6694e+01 -4.6695e+01  4e-04  4e-14  1e-15\n",
      "12: -4.6694e+01 -4.6694e+01  5e-06  3e-14  1e-15\n",
      "Optimal solution found.\n",
      "1770.50064397\n",
      "training for 1 8\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1469e+02 -6.6612e+03  3e+04  2e+00  3e-15\n",
      " 1: -6.4473e+01 -3.0959e+03  5e+03  2e-01  2e-15\n",
      " 2: -5.1691e+01 -7.9899e+02  1e+03  3e-02  2e-15\n",
      " 3: -7.6800e+01 -2.6329e+02  2e+02  6e-03  2e-15\n",
      " 4: -9.2410e+01 -1.4435e+02  5e+01  1e-03  2e-15\n",
      " 5: -9.8364e+01 -1.1956e+02  2e+01  3e-04  1e-15\n",
      " 6: -1.0088e+02 -1.1105e+02  1e+01  2e-13  1e-15\n",
      " 7: -1.0257e+02 -1.0606e+02  3e+00  8e-14  1e-15\n",
      " 8: -1.0324e+02 -1.0426e+02  1e+00  2e-13  1e-15\n",
      " 9: -1.0355e+02 -1.0367e+02  1e-01  4e-14  1e-15\n",
      "10: -1.0359e+02 -1.0359e+02  5e-03  9e-14  1e-15\n",
      "11: -1.0359e+02 -1.0359e+02  1e-04  7e-14  1e-15\n",
      "12: -1.0359e+02 -1.0359e+02  2e-06  3e-14  1e-15\n",
      "Optimal solution found.\n",
      "1891.31667399\n",
      "training for 1 9\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -7.7086e+01 -6.2810e+03  3e+04  2e+00  2e-15\n",
      " 1: -3.6190e+01 -2.7260e+03  4e+03  2e-01  2e-15\n",
      " 2: -2.6916e+01 -5.5124e+02  7e+02  2e-02  2e-15\n",
      " 3: -4.8738e+01 -1.5892e+02  1e+02  3e-03  2e-15\n",
      " 4: -5.9871e+01 -9.4267e+01  4e+01  8e-04  1e-15\n",
      " 5: -6.4611e+01 -7.7166e+01  1e+01  1e-04  1e-15\n",
      " 6: -6.6205e+01 -7.3281e+01  7e+00  8e-06  9e-16\n",
      " 7: -6.7614e+01 -6.9700e+01  2e+00  2e-06  9e-16\n",
      " 8: -6.8024e+01 -6.8779e+01  8e-01  3e-14  9e-16\n",
      " 9: -6.8259e+01 -6.8394e+01  1e-01  2e-13  9e-16\n",
      "10: -6.8310e+01 -6.8315e+01  5e-03  1e-13  9e-16\n",
      "11: -6.8312e+01 -6.8312e+01  1e-04  1e-13  9e-16\n",
      "12: -6.8312e+01 -6.8312e+01  2e-06  2e-14  9e-16\n",
      "Optimal solution found.\n",
      "2014.01811004\n",
      "training for 2 3\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.0404e+02 -8.2833e+03  4e+04  2e+00  4e-15\n",
      " 1: -2.1981e+02 -4.4663e+03  7e+03  3e-01  4e-15\n",
      " 2: -1.8274e+02 -1.0106e+03  1e+03  3e-02  5e-15\n",
      " 3: -2.3561e+02 -4.7608e+02  3e+02  6e-03  4e-15\n",
      " 4: -2.6244e+02 -3.3488e+02  8e+01  1e-03  4e-15\n",
      " 5: -2.7389e+02 -2.9769e+02  2e+01  2e-04  4e-15\n",
      " 6: -2.7877e+02 -2.8539e+02  7e+00  4e-05  4e-15\n",
      " 7: -2.8041e+02 -2.8192e+02  2e+00  3e-06  4e-15\n",
      " 8: -2.8091e+02 -2.8102e+02  1e-01  7e-08  4e-15\n",
      " 9: -2.8095e+02 -2.8095e+02  2e-03  9e-10  4e-15\n",
      "10: -2.8095e+02 -2.8095e+02  4e-05  1e-11  4e-15\n",
      "Optimal solution found.\n",
      "2125.29632592\n",
      "training for 2 4\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.4630e+02 -1.0583e+04  5e+04  3e+00  1e-14\n",
      " 1: -7.4464e+02 -6.9192e+03  9e+03  3e-01  2e-14\n",
      " 2: -7.6719e+02 -1.7237e+03  1e+03  2e-02  2e-14\n",
      " 3: -8.9919e+02 -1.2167e+03  3e+02  4e-03  2e-14\n",
      " 4: -9.4723e+02 -1.0952e+03  1e+02  1e-03  2e-14\n",
      " 5: -9.7572e+02 -1.0167e+03  4e+01  2e-04  2e-14\n",
      " 6: -9.8536e+02 -9.9280e+02  7e+00  1e-05  2e-14\n",
      " 7: -9.8745e+02 -9.8827e+02  8e-01  1e-07  2e-14\n",
      " 8: -9.8772e+02 -9.8774e+02  3e-02  3e-09  2e-14\n",
      " 9: -9.8773e+02 -9.8773e+02  5e-04  5e-11  2e-14\n",
      "Optimal solution found.\n",
      "2234.21911502\n",
      "training for 2 5\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.8703e+02 -7.3989e+03  3e+04  2e+00  3e-15\n",
      " 1: -1.1528e+02 -3.8473e+03  6e+03  2e-01  2e-15\n",
      " 2: -8.4105e+01 -8.9248e+02  1e+03  3e-02  3e-15\n",
      " 3: -1.3537e+02 -2.8753e+02  2e+02  4e-03  2e-15\n",
      " 4: -1.5511e+02 -2.0703e+02  5e+01  7e-04  2e-15\n",
      " 5: -1.6371e+02 -1.8115e+02  2e+01  8e-05  2e-15\n",
      " 6: -1.6703e+02 -1.7283e+02  6e+00  3e-06  1e-15\n",
      " 7: -1.6834e+02 -1.6982e+02  1e+00  7e-14  1e-15\n",
      " 8: -1.6876e+02 -1.6899e+02  2e-01  3e-13  1e-15\n",
      " 9: -1.6884e+02 -1.6885e+02  8e-03  1e-13  1e-15\n",
      "10: -1.6885e+02 -1.6885e+02  1e-04  8e-14  1e-15\n",
      "Optimal solution found.\n",
      "2345.83224392\n",
      "training for 2 6\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.6781e+02 -1.0280e+04  5e+04  3e+00  1e-14\n",
      " 1: -7.7941e+02 -6.5268e+03  8e+03  2e-01  2e-14\n",
      " 2: -8.3083e+02 -1.8673e+03  1e+03  2e-02  2e-14\n",
      " 3: -9.4685e+02 -1.2637e+03  3e+02  5e-03  2e-14\n",
      " 4: -9.9989e+02 -1.0807e+03  8e+01  7e-04  2e-14\n",
      " 5: -1.0159e+03 -1.0374e+03  2e+01  1e-04  2e-14\n",
      " 6: -1.0214e+03 -1.0238e+03  2e+00  8e-06  2e-14\n",
      " 7: -1.0221e+03 -1.0223e+03  2e-01  6e-07  2e-14\n",
      " 8: -1.0222e+03 -1.0222e+03  7e-03  1e-08  2e-14\n",
      " 9: -1.0222e+03 -1.0222e+03  2e-04  2e-10  2e-14\n",
      "Optimal solution found.\n",
      "2454.08674598\n",
      "training for 2 7\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0352e+02 -7.4392e+03  4e+04  2e+00  3e-15\n",
      " 1: -5.2259e+01 -3.7516e+03  6e+03  3e-01  2e-15\n",
      " 2: -1.0077e+01 -8.8825e+02  1e+03  4e-02  5e-15\n",
      " 3: -3.5635e+01 -1.9440e+02  2e+02  5e-03  3e-15\n",
      " 4: -5.4188e+01 -1.0235e+02  5e+01  9e-04  2e-15\n",
      " 5: -6.2019e+01 -7.9857e+01  2e+01  1e-04  1e-15\n",
      " 6: -6.5729e+01 -7.1122e+01  5e+00  5e-06  1e-15\n",
      " 7: -6.7167e+01 -6.8294e+01  1e+00  3e-07  1e-15\n",
      " 8: -6.7544e+01 -6.7677e+01  1e-01  2e-08  1e-15\n",
      " 9: -6.7596e+01 -6.7602e+01  6e-03  1e-13  2e-15\n",
      "10: -6.7599e+01 -6.7599e+01  9e-05  9e-14  1e-15\n",
      "11: -6.7599e+01 -6.7599e+01  3e-06  6e-14  1e-15\n",
      "Optimal solution found.\n",
      "2569.76305795\n",
      "training for 2 8\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.7490e+02 -7.4241e+03  3e+04  2e+00  3e-15\n",
      " 1: -1.9123e+02 -3.9068e+03  6e+03  2e-01  2e-15\n",
      " 2: -1.6914e+02 -1.0114e+03  1e+03  3e-02  3e-15\n",
      " 3: -2.2772e+02 -4.2201e+02  2e+02  5e-03  2e-15\n",
      " 4: -2.5292e+02 -3.0412e+02  5e+01  8e-04  2e-15\n",
      " 5: -2.6267e+02 -2.7651e+02  1e+01  1e-04  2e-15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6: -2.6583e+02 -2.6927e+02  3e+00  2e-05  2e-15\n",
      " 7: -2.6678e+02 -2.6733e+02  6e-01  3e-06  2e-15\n",
      " 8: -2.6696e+02 -2.6699e+02  3e-02  1e-07  2e-15\n",
      " 9: -2.6697e+02 -2.6697e+02  6e-04  2e-09  2e-15\n",
      "10: -2.6697e+02 -2.6697e+02  1e-05  2e-11  2e-15\n",
      "Optimal solution found.\n",
      "2682.92416501\n",
      "training for 2 9\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.3122e+02 -6.8313e+03  3e+04  2e+00  3e-15\n",
      " 1: -6.8632e+01 -3.3021e+03  5e+03  2e-01  2e-15\n",
      " 2: -4.4226e+01 -5.7527e+02  6e+02  2e-02  3e-15\n",
      " 3: -8.9948e+01 -1.9526e+02  1e+02  2e-03  2e-15\n",
      " 4: -1.0529e+02 -1.3890e+02  3e+01  6e-04  1e-15\n",
      " 5: -1.1181e+02 -1.2245e+02  1e+01  1e-04  1e-15\n",
      " 6: -1.1461e+02 -1.1691e+02  2e+00  8e-06  1e-15\n",
      " 7: -1.1534e+02 -1.1566e+02  3e-01  3e-07  1e-15\n",
      " 8: -1.1546e+02 -1.1548e+02  2e-02  4e-09  1e-15\n",
      " 9: -1.1546e+02 -1.1547e+02  5e-04  1e-10  1e-15\n",
      "10: -1.1546e+02 -1.1546e+02  1e-05  2e-12  1e-15\n",
      "Optimal solution found.\n",
      "2794.06880093\n",
      "training for 3 4\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.2846e+02 -7.6683e+03  3e+04  2e+00  6e-15\n",
      " 1: -3.2882e+02 -4.1247e+03  6e+03  2e-01  7e-15\n",
      " 2: -3.0989e+02 -9.4797e+02  7e+02  2e-02  7e-15\n",
      " 3: -3.7592e+02 -5.6057e+02  2e+02  4e-03  6e-15\n",
      " 4: -4.0510e+02 -4.5864e+02  6e+01  7e-04  7e-15\n",
      " 5: -4.1586e+02 -4.3199e+02  2e+01  1e-04  7e-15\n",
      " 6: -4.1976e+02 -4.2383e+02  4e+00  1e-05  7e-15\n",
      " 7: -4.2092e+02 -4.2164e+02  7e-01  5e-13  8e-15\n",
      " 8: -4.2117e+02 -4.2123e+02  6e-02  7e-13  8e-15\n",
      " 9: -4.2119e+02 -4.2119e+02  1e-03  2e-13  8e-15\n",
      "10: -4.2119e+02 -4.2119e+02  2e-05  3e-13  7e-15\n",
      "Optimal solution found.\n",
      "2906.18895888\n",
      "training for 3 5\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.5808e+02 -7.8955e+03  4e+04  2e+00  3e-15\n",
      " 1: -8.8651e+01 -4.1551e+03  7e+03  3e-01  2e-15\n",
      " 2: -4.1501e+01 -1.0107e+03  1e+03  4e-02  3e-15\n",
      " 3: -8.5729e+01 -2.6576e+02  2e+02  5e-03  2e-15\n",
      " 4: -1.0518e+02 -1.7631e+02  8e+01  2e-03  2e-15\n",
      " 5: -1.1475e+02 -1.4040e+02  3e+01  3e-04  1e-15\n",
      " 6: -1.1877e+02 -1.2916e+02  1e+01  2e-13  1e-15\n",
      " 7: -1.2050e+02 -1.2484e+02  4e+00  6e-14  1e-15\n",
      " 8: -1.2142e+02 -1.2270e+02  1e+00  2e-13  1e-15\n",
      " 9: -1.2181e+02 -1.2194e+02  1e-01  4e-13  1e-15\n",
      "10: -1.2186e+02 -1.2187e+02  1e-02  3e-14  1e-15\n",
      "11: -1.2186e+02 -1.2186e+02  2e-04  3e-14  1e-15\n",
      "12: -1.2186e+02 -1.2186e+02  3e-06  3e-13  1e-15\n",
      "Optimal solution found.\n",
      "3026.73975897\n",
      "training for 3 6\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.1433e+02 -9.6131e+03  5e+04  3e+00  7e-15\n",
      " 1: -3.9419e+02 -5.7409e+03  8e+03  3e-01  9e-15\n",
      " 2: -3.6455e+02 -1.3710e+03  1e+03  2e-02  9e-15\n",
      " 3: -4.4119e+02 -7.5464e+02  3e+02  5e-03  8e-15\n",
      " 4: -4.7842e+02 -5.8509e+02  1e+02  5e-04  8e-15\n",
      " 5: -4.9392e+02 -5.2894e+02  4e+01  1e-04  8e-15\n",
      " 6: -4.9931e+02 -5.1319e+02  1e+01  3e-05  8e-15\n",
      " 7: -5.0143e+02 -5.0716e+02  6e+00  9e-13  9e-15\n",
      " 8: -5.0278e+02 -5.0408e+02  1e+00  8e-13  8e-15\n",
      " 9: -5.0315e+02 -5.0328e+02  1e-01  7e-13  9e-15\n",
      "10: -5.0319e+02 -5.0320e+02  4e-03  2e-14  9e-15\n",
      "11: -5.0319e+02 -5.0319e+02  7e-05  2e-13  9e-15\n",
      "Optimal solution found.\n",
      "3144.44418097\n",
      "training for 3 7\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.2836e+01 -7.1347e+03  3e+04  2e+00  2e-15\n",
      " 1: -4.5561e+01 -3.4670e+03  6e+03  2e-01  2e-15\n",
      " 2: -6.5966e+00 -7.3664e+02  1e+03  3e-02  4e-15\n",
      " 3: -2.9623e+01 -1.6707e+02  2e+02  4e-03  2e-15\n",
      " 4: -4.5780e+01 -8.6304e+01  4e+01  9e-04  2e-15\n",
      " 5: -5.2466e+01 -6.7231e+01  2e+01  2e-04  1e-15\n",
      " 6: -5.5594e+01 -6.0481e+01  5e+00  4e-05  1e-15\n",
      " 7: -5.6733e+01 -5.8387e+01  2e+00  6e-06  1e-15\n",
      " 8: -5.7241e+01 -5.7533e+01  3e-01  3e-07  1e-15\n",
      " 9: -5.7346e+01 -5.7382e+01  4e-02  4e-08  1e-15\n",
      "10: -5.7361e+01 -5.7362e+01  7e-04  3e-10  1e-15\n",
      "11: -5.7361e+01 -5.7361e+01  2e-05  6e-12  1e-15\n",
      "Optimal solution found.\n",
      "3260.78281498\n",
      "training for 3 8\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.2223e+02 -8.4141e+03  4e+04  2e+00  3e-15\n",
      " 1: -1.3588e+02 -4.6583e+03  8e+03  3e-01  2e-15\n",
      " 2: -8.2884e+01 -1.3246e+03  2e+03  5e-02  3e-15\n",
      " 3: -1.3866e+02 -4.3341e+02  3e+02  8e-03  2e-15\n",
      " 4: -1.6992e+02 -2.3917e+02  7e+01  1e-03  2e-15\n",
      " 5: -1.8157e+02 -2.0218e+02  2e+01  2e-04  2e-15\n",
      " 6: -1.8572e+02 -1.9211e+02  6e+00  5e-05  2e-15\n",
      " 7: -1.8735e+02 -1.8861e+02  1e+00  4e-06  2e-15\n",
      " 8: -1.8774e+02 -1.8789e+02  1e-01  3e-07  2e-15\n",
      " 9: -1.8779e+02 -1.8780e+02  5e-03  8e-09  2e-15\n",
      "10: -1.8779e+02 -1.8779e+02  1e-04  1e-10  2e-15\n",
      "Optimal solution found.\n",
      "3372.73455787\n",
      "training for 3 9\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1714e+02 -7.2200e+03  3e+04  2e+00  2e-15\n",
      " 1: -5.7504e+01 -3.5569e+03  6e+03  2e-01  2e-15\n",
      " 2: -2.3175e+01 -6.8503e+02  8e+02  2e-02  3e-15\n",
      " 3: -6.5374e+01 -1.7868e+02  1e+02  3e-03  2e-15\n",
      " 4: -8.2099e+01 -1.1645e+02  4e+01  6e-04  1e-15\n",
      " 5: -8.8468e+01 -1.0144e+02  1e+01  1e-04  1e-15\n",
      " 6: -9.1379e+01 -9.5512e+01  4e+00  1e-05  1e-15\n",
      " 7: -9.2466e+01 -9.3422e+01  1e+00  1e-06  1e-15\n",
      " 8: -9.2761e+01 -9.2921e+01  2e-01  9e-08  1e-15\n",
      " 9: -9.2821e+01 -9.2827e+01  6e-03  2e-09  1e-15\n",
      "10: -9.2823e+01 -9.2823e+01  1e-04  4e-11  1e-15\n",
      "11: -9.2823e+01 -9.2823e+01  3e-06  7e-13  1e-15\n",
      "Optimal solution found.\n",
      "3489.63345098\n",
      "training for 4 5\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.5598e+02 -6.9927e+03  3e+04  2e+00  3e-15\n",
      " 1: -8.8657e+01 -3.4857e+03  6e+03  2e-01  2e-15\n",
      " 2: -5.9446e+01 -7.3609e+02  8e+02  2e-02  3e-15\n",
      " 3: -1.0523e+02 -2.6151e+02  2e+02  4e-03  2e-15\n",
      " 4: -1.2171e+02 -1.8069e+02  6e+01  1e-03  2e-15\n",
      " 5: -1.2850e+02 -1.5673e+02  3e+01  3e-13  1e-15\n",
      " 6: -1.3314e+02 -1.4204e+02  9e+00  2e-13  1e-15\n",
      " 7: -1.3446e+02 -1.3849e+02  4e+00  1e-13  1e-15\n",
      " 8: -1.3538e+02 -1.3651e+02  1e+00  3e-14  1e-15\n",
      " 9: -1.3573e+02 -1.3581e+02  8e-02  1e-13  1e-15\n",
      "10: -1.3576e+02 -1.3576e+02  2e-03  9e-14  1e-15\n",
      "11: -1.3576e+02 -1.3576e+02  6e-05  2e-13  1e-15\n",
      "Optimal solution found.\n",
      "3606.42923689\n",
      "training for 4 6\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.9772e+02 -9.6565e+03  4e+04  2e+00  1e-14\n",
      " 1: -7.1427e+02 -5.9961e+03  8e+03  2e-01  2e-14\n",
      " 2: -7.5707e+02 -1.7361e+03  1e+03  3e-02  2e-14\n",
      " 3: -8.6971e+02 -1.1390e+03  3e+02  5e-03  2e-14\n",
      " 4: -9.1628e+02 -1.0034e+03  9e+01  7e-04  2e-14\n",
      " 5: -9.3428e+02 -9.5281e+02  2e+01  8e-05  2e-14\n",
      " 6: -9.3898e+02 -9.4171e+02  3e+00  8e-06  2e-14\n",
      " 7: -9.3981e+02 -9.3998e+02  2e-01  4e-07  2e-14\n",
      " 8: -9.3987e+02 -9.3987e+02  7e-03  1e-08  2e-14\n",
      " 9: -9.3987e+02 -9.3987e+02  2e-04  2e-10  2e-14\n",
      "Optimal solution found.\n",
      "3713.47097087\n",
      "training for 4 7\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.3076e+01 -7.2188e+03  3e+04  2e+00  2e-15\n",
      " 1: -4.4606e+01 -3.5557e+03  6e+03  2e-01  2e-15\n",
      " 2: -6.2621e+00 -7.8910e+02  1e+03  4e-02  4e-15\n",
      " 3: -3.2395e+01 -1.7430e+02  2e+02  4e-03  3e-15\n",
      " 4: -4.9879e+01 -9.0250e+01  4e+01  8e-04  2e-15\n",
      " 5: -5.7061e+01 -7.1118e+01  1e+01  1e-04  1e-15\n",
      " 6: -6.0160e+01 -6.4483e+01  4e+00  1e-05  1e-15\n",
      " 7: -6.1222e+01 -6.2514e+01  1e+00  3e-06  1e-15\n",
      " 8: -6.1633e+01 -6.1812e+01  2e-01  7e-14  1e-15\n",
      " 9: -6.1706e+01 -6.1711e+01  5e-03  3e-14  1e-15\n",
      "10: -6.1709e+01 -6.1709e+01  9e-05  6e-14  1e-15\n",
      "11: -6.1709e+01 -6.1709e+01  2e-06  2e-14  1e-15\n",
      "Optimal solution found.\n",
      "3831.62272501\n",
      "training for 4 8\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.2465e+02 -6.8855e+03  3e+04  2e+00  3e-15\n",
      " 1: -1.4528e+02 -3.4652e+03  5e+03  2e-01  2e-15\n",
      " 2: -1.2473e+02 -7.6671e+02  8e+02  2e-02  3e-15\n",
      " 3: -1.7986e+02 -3.1703e+02  1e+02  3e-03  2e-15\n",
      " 4: -1.9975e+02 -2.3811e+02  4e+01  6e-04  2e-15\n",
      " 5: -2.0764e+02 -2.1714e+02  1e+01  9e-05  2e-15\n",
      " 6: -2.1013e+02 -2.1205e+02  2e+00  1e-05  2e-15\n",
      " 7: -2.1073e+02 -2.1097e+02  2e-01  7e-07  2e-15\n",
      " 8: -2.1081e+02 -2.1082e+02  1e-02  3e-08  2e-15\n",
      " 9: -2.1082e+02 -2.1082e+02  3e-04  6e-10  2e-15\n",
      "10: -2.1082e+02 -2.1082e+02  6e-06  7e-12  2e-15\n",
      "Optimal solution found.\n",
      "3943.88126183\n",
      "training for 4 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1407e+02 -6.5885e+03  3e+04  2e+00  3e-15\n",
      " 1: -5.4731e+01 -3.0743e+03  5e+03  2e-01  2e-15\n",
      " 2: -3.3614e+01 -5.3901e+02  6e+02  2e-02  3e-15\n",
      " 3: -7.3851e+01 -1.8900e+02  1e+02  3e-03  2e-15\n",
      " 4: -8.8826e+01 -1.2601e+02  4e+01  7e-04  1e-15\n",
      " 5: -9.4967e+01 -1.0838e+02  1e+01  2e-04  1e-15\n",
      " 6: -9.7972e+01 -1.0158e+02  4e+00  2e-05  1e-15\n",
      " 7: -9.8948e+01 -9.9746e+01  8e-01  2e-06  9e-16\n",
      " 8: -9.9202e+01 -9.9319e+01  1e-01  2e-07  9e-16\n",
      " 9: -9.9246e+01 -9.9249e+01  3e-03  3e-09  1e-15\n",
      "10: -9.9248e+01 -9.9248e+01  7e-05  7e-11  1e-15\n",
      "Optimal solution found.\n",
      "4056.41380787\n",
      "training for 5 6\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.0533e+02 -7.5506e+03  3e+04  2e+00  3e-15\n",
      " 1: -1.2813e+02 -3.9857e+03  6e+03  2e-01  2e-15\n",
      " 2: -9.5987e+01 -7.8644e+02  8e+02  2e-02  3e-15\n",
      " 3: -1.4760e+02 -3.3431e+02  2e+02  5e-03  2e-15\n",
      " 4: -1.6699e+02 -2.3327e+02  7e+01  1e-03  2e-15\n",
      " 5: -1.7565e+02 -2.0037e+02  3e+01  2e-04  2e-15\n",
      " 6: -1.7993e+02 -1.8778e+02  8e+00  3e-05  2e-15\n",
      " 7: -1.8146e+02 -1.8393e+02  2e+00  2e-13  2e-15\n",
      " 8: -1.8213e+02 -1.8255e+02  4e-01  6e-14  2e-15\n",
      " 9: -1.8227e+02 -1.8229e+02  3e-02  1e-14  2e-15\n",
      "10: -1.8228e+02 -1.8228e+02  4e-04  2e-13  2e-15\n",
      "11: -1.8228e+02 -1.8228e+02  7e-06  3e-14  2e-15\n",
      "Optimal solution found.\n",
      "4172.18084788\n",
      "training for 5 7\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.7910e+02 -8.4574e+03  4e+04  2e+00  1e-14\n",
      " 1: -2.7286e+02 -4.7996e+03  8e+03  3e-01  1e-14\n",
      " 2: -2.3217e+02 -1.1233e+03  1e+03  2e-02  2e-14\n",
      " 3: -3.0157e+02 -5.9118e+02  3e+02  6e-03  1e-14\n",
      " 4: -3.3486e+02 -4.4665e+02  1e+02  1e-03  1e-14\n",
      " 5: -3.5167e+02 -3.9013e+02  4e+01  3e-04  1e-14\n",
      " 6: -3.5933e+02 -3.6849e+02  9e+00  2e-05  1e-14\n",
      " 7: -3.6174e+02 -3.6303e+02  1e+00  6e-07  2e-14\n",
      " 8: -3.6215e+02 -3.6228e+02  1e-01  5e-08  1e-14\n",
      " 9: -3.6219e+02 -3.6220e+02  5e-03  1e-09  2e-14\n",
      "10: -3.6219e+02 -3.6219e+02  9e-05  2e-11  2e-14\n",
      "Optimal solution found.\n",
      "4283.34810185\n",
      "training for 5 8\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.5877e+02 -7.3164e+03  3e+04  2e+00  3e-15\n",
      " 1: -1.6844e+02 -3.8401e+03  5e+03  2e-01  3e-15\n",
      " 2: -1.7506e+02 -7.0557e+02  6e+02  1e-02  4e-15\n",
      " 3: -2.3098e+02 -3.8532e+02  2e+02  3e-03  2e-15\n",
      " 4: -2.5075e+02 -3.0061e+02  5e+01  6e-04  2e-15\n",
      " 5: -2.5761e+02 -2.7802e+02  2e+01  2e-04  2e-15\n",
      " 6: -2.6136e+02 -2.6687e+02  6e+00  1e-05  2e-15\n",
      " 7: -2.6251e+02 -2.6379e+02  1e+00  5e-13  2e-15\n",
      " 8: -2.6285e+02 -2.6299e+02  1e-01  1e-13  2e-15\n",
      " 9: -2.6289e+02 -2.6290e+02  5e-03  3e-13  2e-15\n",
      "10: -2.6290e+02 -2.6290e+02  1e-04  4e-13  2e-15\n",
      "Optimal solution found.\n",
      "4394.33088589\n",
      "training for 5 9\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.7302e+02 -7.5652e+03  3e+04  2e+00  4e-15\n",
      " 1: -1.9616e+02 -4.0285e+03  6e+03  2e-01  4e-15\n",
      " 2: -1.7674e+02 -7.9849e+02  7e+02  2e-02  5e-15\n",
      " 3: -2.2908e+02 -4.2790e+02  2e+02  4e-03  3e-15\n",
      " 4: -2.5164e+02 -3.1447e+02  6e+01  7e-04  3e-15\n",
      " 5: -2.6163e+02 -2.8082e+02  2e+01  2e-05  3e-15\n",
      " 6: -2.6538e+02 -2.6993e+02  5e+00  7e-07  3e-15\n",
      " 7: -2.6630e+02 -2.6772e+02  1e+00  8e-14  3e-15\n",
      " 8: -2.6665e+02 -2.6698e+02  3e-01  5e-14  3e-15\n",
      " 9: -2.6674e+02 -2.6679e+02  5e-02  3e-13  3e-15\n",
      "10: -2.6676e+02 -2.6676e+02  1e-03  2e-14  3e-15\n",
      "11: -2.6676e+02 -2.6676e+02  1e-05  3e-13  3e-15\n",
      "Optimal solution found.\n",
      "4511.367419\n",
      "training for 6 7\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1028e+02 -7.5103e+03  4e+04  2e+00  3e-15\n",
      " 1: -5.6897e+01 -3.8143e+03  7e+03  3e-01  2e-15\n",
      " 2: -1.3830e+01 -9.2363e+02  1e+03  4e-02  4e-15\n",
      " 3: -3.9528e+01 -1.9616e+02  2e+02  4e-03  3e-15\n",
      " 4: -5.5680e+01 -1.2195e+02  7e+01  2e-03  2e-15\n",
      " 5: -6.4887e+01 -8.8241e+01  2e+01  1e-04  2e-15\n",
      " 6: -6.9418e+01 -7.6829e+01  7e+00  2e-05  1e-15\n",
      " 7: -7.1201e+01 -7.3118e+01  2e+00  2e-06  1e-15\n",
      " 8: -7.1797e+01 -7.2062e+01  3e-01  1e-07  1e-15\n",
      " 9: -7.1900e+01 -7.1908e+01  8e-03  2e-09  2e-15\n",
      "10: -7.1903e+01 -7.1903e+01  1e-04  3e-11  2e-15\n",
      "11: -7.1903e+01 -7.1903e+01  2e-06  3e-13  2e-15\n",
      "Optimal solution found.\n",
      "4627.79843497\n",
      "training for 6 8\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.3801e+02 -8.0319e+03  4e+04  2e+00  3e-15\n",
      " 1: -2.4315e+02 -4.4272e+03  7e+03  2e-01  3e-15\n",
      " 2: -2.2086e+02 -9.6970e+02  9e+02  2e-02  3e-15\n",
      " 3: -2.8364e+02 -5.1393e+02  2e+02  5e-03  2e-15\n",
      " 4: -3.1190e+02 -3.6929e+02  6e+01  3e-04  2e-15\n",
      " 5: -3.2242e+02 -3.3848e+02  2e+01  4e-05  2e-15\n",
      " 6: -3.2587e+02 -3.2978e+02  4e+00  6e-06  2e-15\n",
      " 7: -3.2693e+02 -3.2738e+02  4e-01  4e-07  2e-15\n",
      " 8: -3.2708e+02 -3.2710e+02  2e-02  1e-08  2e-15\n",
      " 9: -3.2708e+02 -3.2709e+02  5e-04  2e-10  2e-15\n",
      "10: -3.2708e+02 -3.2708e+02  1e-05  3e-12  2e-15\n",
      "Optimal solution found.\n",
      "4739.78852892\n",
      "training for 6 9\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.3972e+02 -6.9017e+03  3e+04  2e+00  2e-15\n",
      " 1: -7.4093e+01 -3.3717e+03  5e+03  2e-01  2e-15\n",
      " 2: -4.9322e+01 -5.8506e+02  6e+02  2e-02  3e-15\n",
      " 3: -9.5462e+01 -2.0704e+02  1e+02  3e-03  2e-15\n",
      " 4: -1.1120e+02 -1.4547e+02  4e+01  6e-04  1e-15\n",
      " 5: -1.1785e+02 -1.2868e+02  1e+01  6e-05  1e-15\n",
      " 6: -1.2042e+02 -1.2319e+02  3e+00  8e-06  1e-15\n",
      " 7: -1.2125e+02 -1.2164e+02  4e-01  4e-07  1e-15\n",
      " 8: -1.2138e+02 -1.2141e+02  2e-02  7e-09  1e-15\n",
      " 9: -1.2139e+02 -1.2139e+02  7e-04  2e-10  1e-15\n",
      "10: -1.2139e+02 -1.2139e+02  1e-05  3e-12  1e-15\n",
      "Optimal solution found.\n",
      "4851.10654283\n",
      "training for 7 8\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.4021e+02 -7.5807e+03  4e+04  2e+00  3e-15\n",
      " 1: -7.7474e+01 -3.9413e+03  7e+03  3e-01  3e-15\n",
      " 2: -3.7302e+01 -1.0367e+03  1e+03  4e-02  3e-15\n",
      " 3: -7.4177e+01 -2.7628e+02  2e+02  6e-03  3e-15\n",
      " 4: -9.3886e+01 -1.5833e+02  7e+01  1e-03  2e-15\n",
      " 5: -1.0307e+02 -1.2356e+02  2e+01  3e-04  2e-15\n",
      " 6: -1.0675e+02 -1.1333e+02  7e+00  5e-05  2e-15\n",
      " 7: -1.0821e+02 -1.0986e+02  2e+00  6e-06  2e-15\n",
      " 8: -1.0865e+02 -1.0897e+02  3e-01  7e-07  2e-15\n",
      " 9: -1.0875e+02 -1.0879e+02  4e-02  6e-08  2e-15\n",
      "10: -1.0876e+02 -1.0876e+02  1e-03  1e-09  2e-15\n",
      "11: -1.0876e+02 -1.0876e+02  2e-05  2e-11  2e-15\n",
      "Optimal solution found.\n",
      "4968.56085896\n",
      "training for 7 9\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.8746e+02 -9.5957e+03  5e+04  3e+00  8e-15\n",
      " 1: -2.8432e+02 -5.5742e+03  9e+03  3e-01  9e-15\n",
      " 2: -2.5152e+02 -1.4261e+03  1e+03  3e-02  9e-15\n",
      " 3: -3.0818e+02 -7.0514e+02  4e+02  9e-03  8e-15\n",
      " 4: -3.4189e+02 -4.9364e+02  2e+02  2e-03  9e-15\n",
      " 5: -3.5935e+02 -4.1679e+02  6e+01  4e-04  9e-15\n",
      " 6: -3.6813e+02 -3.8647e+02  2e+01  2e-13  1e-14\n",
      " 7: -3.7153e+02 -3.7782e+02  6e+00  2e-13  9e-15\n",
      " 8: -3.7293e+02 -3.7451e+02  2e+00  1e-13  1e-14\n",
      " 9: -3.7345e+02 -3.7358e+02  1e-01  4e-13  1e-14\n",
      "10: -3.7350e+02 -3.7350e+02  4e-03  9e-14  1e-14\n",
      "11: -3.7350e+02 -3.7350e+02  8e-05  8e-13  1e-14\n",
      "Optimal solution found.\n",
      "5086.26259184\n",
      "training for 8 9\n",
      "Training on gaussian kernel\n",
      "Finding the optimal solution:\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.5990e+02 -7.2285e+03  3e+04  2e+00  3e-15\n",
      " 1: -7.8001e+01 -3.7404e+03  6e+03  2e-01  2e-15\n",
      " 2: -5.8062e+01 -7.5437e+02  8e+02  2e-02  4e-15\n",
      " 3: -1.2171e+02 -2.6113e+02  1e+02  3e-03  2e-15\n",
      " 4: -1.4164e+02 -1.8153e+02  4e+01  6e-04  2e-15\n",
      " 5: -1.4951e+02 -1.6040e+02  1e+01  6e-05  1e-15\n",
      " 6: -1.5210e+02 -1.5479e+02  3e+00  8e-06  1e-15\n",
      " 7: -1.5284e+02 -1.5330e+02  5e-01  9e-07  1e-15\n",
      " 8: -1.5299e+02 -1.5303e+02  4e-02  5e-08  1e-15\n",
      " 9: -1.5300e+02 -1.5301e+02  7e-04  8e-10  1e-15\n",
      "10: -1.5300e+02 -1.5300e+02  1e-05  1e-11  1e-15\n",
      "Optimal solution found.\n",
      "5199.81085682\n"
     ]
    }
   ],
   "source": [
    "# fill upper triangle with alphas\n",
    "Yi = np.ones(2250).astype(float)\n",
    "st = time.time()\n",
    "for i in range(0,10):\n",
    "    for j in range(i+1,10):\n",
    "        print(\"training for \"+str(i) + \" \" + str(j))\n",
    "        trainX = np.vstack((X[i],X[j]))\n",
    "        # treating bigger class as 1 and smaller as -1\n",
    "        trainY = np.asarray([np.hstack((-1.0*Yi,Yi))]).astype(float)\n",
    "        GP = np.eye(len(trainX)).astype(float)\n",
    "        M = len(trainX)\n",
    "        for f in range(0,M):\n",
    "#             t = trainX - trainX[f]\n",
    "#             GP[f] = np.sum(t*t,axis=1)\n",
    "            GP[f] = np.sum((trainX - trainX[f])**2,axis=1)\n",
    "        GP = GAUS(y,GP)\n",
    "        ALPHAxY[i][j] = (traingaus(GP,trainY,M) * trainY.T)\n",
    "        b[i][j] = getB(ALPHAxY[i][j],GP)\n",
    "        print(time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save generated Alphaxy and B\n",
    "np.save('alphxy.npy',ALPHAxY.astype(np.float32))\n",
    "np.save('b.npy',b)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "total time reqd = 5199.81085682\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing, returns accuracy and cnfmat, assuming ALPHAxY and b are defined globally\n",
    "def testing(tX,tY):\n",
    "    M = 4500\n",
    "    Votes = np.zeros((45,len(tX))).astype(np.int64)\n",
    "    tx = np.ones((M,len(tX))).astype(float)\n",
    "    st = time.time()\n",
    "    index = 0\n",
    "    # Iterate over all i,j to get vote from each classifier\n",
    "    for i in range(0,10):\n",
    "        for j in range(i+1,10):\n",
    "            print(\"Voting b/w classes \"+str(i) + \" and \"+ str(j))\n",
    "            trainX = np.vstack((X[i],X[j]))\n",
    "            for k in range(0,M):\n",
    "                tx[k] = np.sum((tX - trainX[k])**2,axis = 1)\n",
    "            fW = ALPHAxY[i][j]\n",
    "            R = np.sum(fW * GAUS(y,tx), axis=0) + b[i][j]\n",
    "            # converting values to classes\n",
    "            v = [j if cls>=0 else i for cls in R]\n",
    "            Votes[index] = v\n",
    "            index+=1\n",
    "    Votes = Votes.T\n",
    "    # Create Final class from votes, tie ends with assigning max class\n",
    "    R = np.zeros(len(tX))\n",
    "    for i in range(0,len(tX)):\n",
    "        tmp = np.bincount(Votes[i])\n",
    "        R[i] = np.where(tmp == tmp.max())[0][-1]\n",
    "    cnfmat = np.zeros((10,10))\n",
    "    # Number of correct predictions\n",
    "    correct = len(np.where(R == tY)[0])\n",
    "    accuracy = float(correct)/float(len(tY))\n",
    "    for i in range(0,len(tY)):\n",
    "        cnfmat[int(R[i])][int(tY[i])] +=1\n",
    "    return (accuracy,cnfmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "tX = tdata[:,0:784]/255.0\n",
    "tY = tdata[:,-1]\n",
    "(TestAccuracy, TestConfusionMatrix) = testing(tX,tY)\n",
    "print(\"Test Accuracy: \"+str(TestAccuracy))\n",
    "print(\"Confusion Matrix for Test data:\")\n",
    "print(TestConfusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data\n",
    "vX = vdata[:,0:784]/255.0\n",
    "vY = vdata[:,-1]\n",
    "(ValidationAccuracy,ValidationConfusionMatrix) = testing(vX,vY)\n",
    "print(\"Validation Accuracy: \"+str(ValidationAccuracy))\n",
    "print(\"Confusion Matrix for Validation data:\")\n",
    "print(ValidationConfusionMatrix)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Test Accuracy = 0.8484\n",
    "Validation Accuracy = 84.6"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Val cnfmat\n",
    "array([[199.,   0.,   1.,   8.,   0.,   0.,  19.,   0.,   0.,   0.],\n",
    "       [  2., 240.,   0.,   7.,   2.,   0.,   0.,   0.,   0.,   0.],\n",
    "       [  1.,   2., 208.,   0.,  29.,   0.,  26.,   0.,   1.,   0.],\n",
    "       [  4.,   2.,   1., 193.,   4.,   1.,   1.,   0.,   0.,   0.],\n",
    "       [  0.,   0.,  13.,   6., 185.,   0.,  11.,   0.,   0.,   0.],\n",
    "       [  0.,   0.,   0.,   0.,   0., 226.,   0.,  24.,   0.,   2.],\n",
    "       [ 37.,   3.,  15.,  26.,  21.,   0., 183.,   0.,   2.,   0.],\n",
    "       [  0.,   0.,   0.,   0.,   0.,   1.,   0., 198.,   2.,   4.],\n",
    "       [  7.,   3.,  12.,  10.,   9.,  15.,  10.,   5., 245.,   5.],\n",
    "       [  0.,   0.,   0.,   0.,   0.,   7.,   0.,  23.,   0., 239.]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Test cnfmat \n",
    "array([[399.,   0.,   0.,  12.,   0.,   1.,  52.,   0.,   1.,   0.],\n",
    "       [  0., 484.,   0.,   9.,   1.,   0.,   1.,   0.,   0.,   0.],\n",
    "       [  7.,   6., 414.,   2.,  52.,   0.,  51.,   0.,   1.,   0.],\n",
    "       [  7.,   2.,   3., 407.,  11.,   0.,   4.,   0.,   0.,   0.],\n",
    "       [  0.,   0.,  26.,   7., 367.,   0.,  19.,   0.,   0.,   0.],\n",
    "       [  0.,   0.,   0.,   0.,   0., 432.,   0.,  48.,   0.,   5.],\n",
    "       [ 64.,   6.,  43.,  43.,  54.,   0., 347.,   0.,   3.,   0.],\n",
    "       [  0.,   0.,   0.,   0.,   0.,   7.,   0., 410.,   0.,   6.],\n",
    "       [ 23.,   2.,  14.,  20.,  15.,  46.,  26.,   6., 495.,   2.],\n",
    "       [  0.,   0.,   0.,   0.,   0.,  14.,   0.,  36.,   0., 487.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi class using SK learn 1 vs 1\n",
    "# Initialize classifier\n",
    "classifier = multiclass.OneVsOneClassifier(svm.SVC(kernel='rbf',C=1,gamma=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251.799129009\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "st = time.time()\n",
    "classifier.fit(allX,Y)\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming classifier is global\n",
    "def svmtesting(tX,tY):\n",
    "    R = classifier.predict(tX)\n",
    "    cnfmat = np.zeros((10,10)).astype(int)\n",
    "    correct = len(np.where(R==tY)[0])\n",
    "    for i in range(0,len(R)):\n",
    "        cnfmat[int(R[i])][int(tY[i])]+=1\n",
    "    accuracy = float(correct)/float(len(tY))\n",
    "    return (accuracy,cnfmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.881\n",
      "Confusion Matrix for Test data:\n",
      "[[433   1   5  12   2   0  80   0   1   0]\n",
      " [  0 482   0   0   1   0   0   0   0   0]\n",
      " [  5   4 410   3  39   0  53   0   1   0]\n",
      " [ 11   9   7 457  14   0   9   0   1   0]\n",
      " [  3   0  37   9 399   0  34   0   2   0]\n",
      " [  0   0   0   0   0 473   0  14   2  11]\n",
      " [ 38   4  33  14  39   0 317   0   2   0]\n",
      " [  0   0   0   0   0  16   0 471   2  14]\n",
      " [ 10   0   8   5   6   5   7   1 489   1]\n",
      " [  0   0   0   0   0   6   0  14   0 474]]\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "tX = tdata[:,0:784]/255.0\n",
    "tY = tdata[:,-1]\n",
    "(TestAccuracy, TestConfusionMatrix) = svmtesting(tX,tY)\n",
    "print(\"Test Accuracy: \"+str(TestAccuracy))\n",
    "print(\"Confusion Matrix for Test data:\")\n",
    "print(TestConfusionMatrix)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Test Accuracy: 0.881\n",
    "Confusion Matrix for Test data:\n",
    "[[433   1   5  12   2   0  80   0   1   0]\n",
    " [  0 482   0   0   1   0   0   0   0   0]\n",
    " [  5   4 410   3  39   0  53   0   1   0]\n",
    " [ 11   9   7 457  14   0   9   0   1   0]\n",
    " [  3   0  37   9 399   0  34   0   2   0]\n",
    " [  0   0   0   0   0 473   0  14   2  11]\n",
    " [ 38   4  33  14  39   0 317   0   2   0]\n",
    " [  0   0   0   0   0  16   0 471   2  14]\n",
    " [ 10   0   8   5   6   5   7   1 489   1]\n",
    " [  0   0   0   0   0   6   0  14   0 474]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8788\n",
      "Confusion Matrix for Validation data:\n",
      "[[212   0   5   6   1   0  33   0   0   0]\n",
      " [  0 237   0   0   1   0   0   0   0   0]\n",
      " [  1   3 205   0  24   0  28   0   1   0]\n",
      " [  8   7   3 228   8   1   4   0   1   0]\n",
      " [  0   0  19   6 200   0  19   0   1   0]\n",
      " [  0   0   0   0   0 241   0   8   0   5]\n",
      " [ 26   2  13   9  15   0 165   0   1   0]\n",
      " [  0   0   0   0   0   2   0 230   2   8]\n",
      " [  3   1   5   1   1   1   1   1 244   2]\n",
      " [  0   0   0   0   0   5   0  11   0 235]]\n"
     ]
    }
   ],
   "source": [
    "# Validation data\n",
    "vX = vdata[:,0:784]/255.0\n",
    "vY = vdata[:,-1]\n",
    "(ValidationAccuracy,ValidationConfusionMatrix) = svmtesting(vX,vY)\n",
    "print(\"Validation Accuracy: \"+str(ValidationAccuracy))\n",
    "print(\"Confusion Matrix for Validation data:\")\n",
    "print(ValidationConfusionMatrix)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Validation Accuracy: 0.8788\n",
    "Confusion Matrix for Validation data:\n",
    "[[212   0   5   6   1   0  33   0   0   0]\n",
    " [  0 237   0   0   1   0   0   0   0   0]\n",
    " [  1   3 205   0  24   0  28   0   1   0]\n",
    " [  8   7   3 228   8   1   4   0   1   0]\n",
    " [  0   0  19   6 200   0  19   0   1   0]\n",
    " [  0   0   0   0   0 241   0   8   0   5]\n",
    " [ 26   2  13   9  15   0 165   0   1   0]\n",
    " [  0   0   0   0   0   2   0 230   2   8]\n",
    " [  3   1   5   1   1   1   1   1 244   2]\n",
    " [  0   0   0   0   0   5   0  11   0 235]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [1e-5,1e-3,1,5,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "AX = allX\n",
    "AY = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIM = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "allX = AX[0:LIM]\n",
    "Y = AY[0:LIM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX = tdata[0:LIM,0:784]/255.0\n",
    "tY = tdata[0:LIM,-1]\n",
    "vX = vdata[:,0:784]/255.0\n",
    "vY = vdata[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 1\n",
      "Block 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-20a6430ee4d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtrainY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dhull/.conda/envs/ocr/lib/python2.7/site-packages/sklearn/multiclass.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mmulti\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \"\"\"\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dhull/.conda/envs/ocr/lib/python2.7/site-packages/sklearn/multiclass.pyc\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    614\u001b[0m                                  for est, Xi in zip(self.estimators_, Xs)]).T\n\u001b[1;32m    615\u001b[0m         confidences = np.vstack([_predict_binary(est, Xi)\n\u001b[0;32m--> 616\u001b[0;31m                                  for est, Xi in zip(self.estimators_, Xs)]).T\n\u001b[0m\u001b[1;32m    617\u001b[0m         Y = _ovr_decision_function(predictions,\n\u001b[1;32m    618\u001b[0m                                    confidences, len(self.classes_))\n",
      "\u001b[0;32m/home/dhull/.conda/envs/ocr/lib/python2.7/site-packages/sklearn/multiclass.pyc\u001b[0m in \u001b[0;36m_predict_binary\u001b[0;34m(estimator, X)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# probabilities of the positive class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dhull/.conda/envs/ocr/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0minterpreting\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;32mfrom\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mhyperplane\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;32min\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfurther\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \"\"\"\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0mdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function_shape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ovr'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_ovr_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dhull/.conda/envs/ocr/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdec_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mdec_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;31m# In binary case, we need to flip the sign of coef, intercept and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dhull/.conda/envs/ocr/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_dense_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLIBSVM_IMPL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             coef0=self.coef0, gamma=self._gamma)\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sparse_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# K-cross validation\n",
    "# assuming data is already shuffled\n",
    "k = 5\n",
    "BS = allX.shape[0]/k\n",
    "Accuracies=[]\n",
    "st = time.time()\n",
    "for c in Cs:\n",
    "    correct = 0\n",
    "    clf = multiclass.OneVsOneClassifier(svm.SVC(kernel='rbf',C=c,gamma=0.05))\n",
    "    # Treat i-th block as validation set\n",
    "    for i in range(0,k):\n",
    "        print(\"Block \"+str(i+1))\n",
    "        trainX = np.vstack((allX[:i*BS],allX[(i+1)*BS:]))\n",
    "        trainY = np.hstack((Y[:i*BS],Y[(i+1)*BS:]))\n",
    "        clf.fit(trainX,trainY)\n",
    "        R = clf.predict(allX[i*BS:(i+1)*BS])\n",
    "        y = Y[i*BS:(i+1)*BS]\n",
    "        correct += len(np.where(R==y)[0])\n",
    "    Accuracy = float(correct)/float(len(allX))\n",
    "    Accuracies.append(Accuracy)\n",
    "    print(\"C: \"+str(c)+\", \" + \"Average Validation accuracy: \"+str(Accuracy))\n",
    "print(Accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test and Validation Accuracies\n",
    "TestAccuracies = []\n",
    "ValidationAccuracies = []\n",
    "for c in Cs:\n",
    "    clf = multiclass.OneVsOneClassifier(svm.SVC(kernel='rbf',C=c,gamma=0.05))\n",
    "    clf.fit(allX,Y)\n",
    "    testCorrect = len(np.where(clf.predict(tX)==tY)[0])\n",
    "    testAccuracy = float(testCorrect)/float(len(tY)) \n",
    "    TestAccuracies.append(testAccuracy)\n",
    "    validationCorrect = len(np.where(clf.predict(vX)==vY)[0])\n",
    "    validationAccuracy = float(validationCorrect)/float(len(vY))\n",
    "    ValidationAccuracies.append(validationAccuracy)\n",
    "    print(\"C: \"+str(c)+\", Test data Accuracy: \"+str(testAccuracy)+\", Validation data Accuracy: \"+str(validationAccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Cs,Accuracies)\n",
    "plt.plot(Cs,TestAccuracies,marker='x')\n",
    "plt.plot(Cs,ValidationAccuracies,marker='+')\n",
    "plt.title(\"Accuracies vs C\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.savefig('Accuracies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
